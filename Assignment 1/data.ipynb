{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cost_mail = 10\n",
    "\n",
    "perc_accep_over50k = 0.1\n",
    "avg_profit_over50k = 980\n",
    "\n",
    "perc_accep_under50k = 0.05\n",
    "avg_cost_under50k = -310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedo/miniconda3/envs/data-mining/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('data/existing-customers.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can se there's multiple instances where there are missing values. This occurs only in columns that have categorical features. The way we andle that is by creating new column also for the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowID                0\n",
      "age                  0\n",
      "workclass         1836\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     583\n",
      "class                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data given is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=50K    24720\n",
      ">50K      7841\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['class'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedo/miniconda3/envs/data-mining/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df.drop('education', inplace=True, axis=1)\n",
    "df['capital'] = df['capital-gain'] - df['capital-loss']\n",
    "df.drop('capital-gain', inplace=True, axis=1)\n",
    "df.drop('capital-loss', inplace=True, axis=1)\n",
    "\n",
    "label = preprocessing.LabelEncoder()\n",
    "df['sex'] = label.fit_transform(df['sex'])\n",
    "\n",
    "categorical_cols = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'native-country']\n",
    "\n",
    "# Use OneHotEncoder to create a sparse matrix of one-hot encoded columns\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "encoded_cols = encoder.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Create a new DataFrame with the encoded columns and drop the original categorical columns\n",
    "encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "df.drop(categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Concatenate the encoded columns with the original DataFrame\n",
    "df = pd.concat([df, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 91)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].replace(['<=50K', '>50K'],[0, 1], inplace=True)\n",
    "\n",
    "X = df.drop(['RowID', 'class'], axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dt = dt.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = dt.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8094287469287469\n",
      "Precision: 0.6210392902408112\n",
      "Recall: 0.6038200862600123\n",
      "F1 score: 0.612308653545767\n",
      "ROC AUC: 0.7407523421686644\n",
      "Expected value:  13.748310810810814\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_val, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_val, y_pred))\n",
    "print(\"F1 score:\",metrics.f1_score(y_val, y_pred))\n",
    "print(\"ROC AUC:\",metrics.roc_auc_score(y_val, y_pred))\n",
    "\n",
    "n = len(y_pred)\n",
    "n_1 = sum(y_pred)\n",
    "precision = metrics.precision_score(y_val, y_pred)\n",
    "exp_val = (n_1/n) * (precision * perc_accep_over50k * avg_profit_over50k - (1- precision) * perc_accep_under50k * avg_cost_under50k - cost_mail)\n",
    "print('Expected value: ', exp_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "neigh = neigh.fit(X_train,y_train)\n",
    "\n",
    "y_pred = neigh.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8335380835380836\n",
      "Precision: 0.6733118971061093\n",
      "Recall: 0.6451016635859519\n",
      "F1 score: 0.6589049716803019\n",
      "ROC AUC: 0.7705974670967191\n",
      "Expected value:  14.577702702702702\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_val, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_val, y_pred))\n",
    "print(\"F1 score:\",metrics.f1_score(y_val, y_pred))\n",
    "print(\"ROC AUC:\",metrics.roc_auc_score(y_val, y_pred))\n",
    "\n",
    "n_1 = sum(y_pred)\n",
    "precision = metrics.precision_score(y_val, y_pred)\n",
    "exp_val = (n_1/n) * (precision * perc_accep_over50k * avg_profit_over50k - (1- precision) * perc_accep_under50k * avg_cost_under50k - cost_mail)\n",
    "print('Expected value: ', exp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7716523341523341\n",
      "Precision: 0.52660406885759\n",
      "Recall: 0.829328404189772\n",
      "F1 score: 0.6441732471883226\n",
      "ROC AUC: 0.7909170145309671\n",
      "Expected value:  19.211148648648653\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_val, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_val, y_pred))\n",
    "print(\"F1 score:\",metrics.f1_score(y_val, y_pred))\n",
    "print(\"ROC AUC:\",metrics.roc_auc_score(y_val, y_pred))\n",
    "\n",
    "n_1 = sum(y_pred)\n",
    "precision = metrics.precision_score(y_val, y_pred)\n",
    "exp_val = (n_1/n) * (precision * perc_accep_over50k * avg_profit_over50k - (1- precision) * perc_accep_under50k * avg_cost_under50k - cost_mail)\n",
    "print('Expected value: ', exp_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf = rf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.835534398034398\n",
      "Precision: 0.6965811965811965\n",
      "Recall: 0.6025878003696857\n",
      "F1 score: 0.6461843409316155\n",
      "ROC AUC: 0.7577267085301078\n",
      "Expected value:  13.576013513513512\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_val, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_val, y_pred))\n",
    "print(\"F1 score:\",metrics.f1_score(y_val, y_pred))\n",
    "print(\"ROC AUC:\",metrics.roc_auc_score(y_val, y_pred))\n",
    "\n",
    "n_1 = sum(y_pred)\n",
    "precision = metrics.precision_score(y_val, y_pred)\n",
    "exp_val = (n_1/n) * (precision * perc_accep_over50k * avg_profit_over50k - (1- precision) * perc_accep_under50k * avg_cost_under50k - cost_mail)\n",
    "print('Expected value: ', exp_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Classifier chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7709196990634116\n",
      "Precision: 0.49899071457408156\n",
      "Recall: 0.8312037659717552\n",
      "F1 score: 0.6236125126135217\n",
      "ROC AUC: 0.7921438646810627\n",
      "Expected value:  17.748119146322743\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\",metrics.f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\",metrics.roc_auc_score(y_test, y_pred))\n",
    "\n",
    "n = len(y_pred)\n",
    "n_1 = sum(y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "exp_val = (n_1/n) * (precision * perc_accep_over50k * avg_profit_over50k - (1- precision) * perc_accep_under50k * avg_cost_under50k - cost_mail)\n",
    "print('Expected value: ', exp_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential coustomers prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedo/miniconda3/envs/data-mining/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('data/potential-customers.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('education', inplace=True, axis=1)\n",
    "df['capital'] = df['capital-gain'] - df['capital-loss']\n",
    "df.drop('capital-gain', inplace=True, axis=1)\n",
    "df.drop('capital-loss', inplace=True, axis=1)\n",
    "\n",
    "df['sex'] = label.fit_transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cols = encoder.transform(df[categorical_cols])\n",
    "# Create a new DataFrame with the encoded columns and drop the original categorical columns\n",
    "encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "df.drop(categorical_cols, axis=1, inplace=True)\n",
    "# Concatenate the encoded columns with the original DataFrame\n",
    "df = pd.concat([df, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(df.drop(['RowID'], axis=1))\n",
    "\n",
    "over_50k = ['Row'+str(i) for i in range(len(y_pred)) if y_pred[i] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('potential-customers-above-50k.txt', 'w') as f:\n",
    "    for item in over_50k:\n",
    "        f.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers over 50k:  6118\n",
      "Profit:  346687.07832054904\n",
      "Mailing costs:  61180\n",
      "Expected Revenues:  285507.07832054904\n"
     ]
    }
   ],
   "source": [
    "n = len(over_50k)\n",
    "cost_mail = n * 10\n",
    "profit = n * (precision * perc_accep_over50k * avg_profit_over50k - (1- precision) * perc_accep_under50k * avg_cost_under50k)\n",
    "\n",
    "revenue = profit - cost_mail\n",
    "\n",
    "print('Number of customers over 50k: ', n)\n",
    "print('Profit: ', profit)\n",
    "print('Mailing costs: ', cost_mail)\n",
    "print('Expected Revenues: ', revenue)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bbdbab4b95dbf358a5e6124fbb75fd494980f3264aed9857fdb41efb5da82f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
